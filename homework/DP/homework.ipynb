{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinyin\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    # we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_to_pinyin(character):\n",
    "    ret = []\n",
    "    character_clean = [''.join(token(str(a))) for a in character]\n",
    "    for word in character_clean:\n",
    "        ret += [pinyin.get(word,format='strip', delimiter=' ')]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    ret = []\n",
    "    with open( './article_9k.txt', 'r' ) as f:\n",
    "        for line in f.readlines():\n",
    "            ret += chinese_to_pinyin(line)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinyin_counter(token):\n",
    "    return Counter(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ciwai',\n",
       " 'waizi',\n",
       " 'ziben',\n",
       " 'benzhou',\n",
       " 'zhou6',\n",
       " '6yue',\n",
       " 'yue1',\n",
       " '12',\n",
       " '2ri',\n",
       " 'riqi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN = get_token()\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "TOKEN_2_GRAM[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('n', 683571),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count = pinyin_counter(TOKEN)\n",
    "words_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return (words_count[word] + 1) / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: \n",
    "        return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(spell):\n",
    "    global split_sentence\n",
    "    left_word = ''\n",
    "    right_word = ''\n",
    "    sentence = ''\n",
    "    list_sentence = []\n",
    "    prob = 0\n",
    "    for i in range(2,len(spell)+1):\n",
    "        left_word = spell[0:i]\n",
    "        right_word = spell[i:]\n",
    "        #print('left_word:{},right_word:{}'.format(left_word,right_word))\n",
    "        \n",
    "        if right_word == '':\n",
    "            prob = prob_1(left_word)\n",
    "            list_sentence += [(left_word, prob)]\n",
    "            \n",
    "        for i2 in range(2,len(right_word)+1):\n",
    "            left_word2 = right_word[0:i2]\n",
    "            right_word2 = right_word[i2:]\n",
    "            sentence = left_word + ' ' + left_word2\n",
    "            prob = prob_2(left_word, left_word2)\n",
    "            list_sentence += [(sentence, prob)]\n",
    "    #print(list_sentence)\n",
    "    (select_sentence, select_pro) = max(list_sentence, key=lambda x: x[1])\n",
    "    split_sentence += [(select_sentence, select_pro)]\n",
    "    \n",
    "    left_spell = spell[len(select_sentence)-1:]\n",
    "    if left_spell != '' and spell != select_sentence:\n",
    "        split_words(left_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ni hao wo zai zh eli \n"
     ]
    }
   ],
   "source": [
    "split_sentence = []\n",
    "split_words('nihaowozaizheli')\n",
    "\n",
    "sentence = ''\n",
    "for item in split_sentence:\n",
    "    sentence += item[0] + ' '\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
